{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "red_tfg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSmukMCFx0Dw"
      },
      "outputs": [],
      "source": [
        "\" @author: Pedro :') \"\n",
        "\"\"\n",
        "#Importamos módulos y librerías necesarias\n",
        "import itertools\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow import keras\n",
        "\n",
        "import PIL\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "from tensorflow import math\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "from PIL import Image\n",
        "from tensorflow.math import confusion_matrix\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fap0TWDGKCYR"
      },
      "outputs": [],
      "source": [
        "## DEFINIMOS FUNCIONES IMPORTANTES PARA GRADCAM\n",
        "\n",
        "#Función de convertir la imagen en un determinado path a una array\n",
        "def get_img_array(img_path, img_size):\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    img_array = np.expand_dims(array, axis=0)\n",
        "    return img_array\n",
        "        \n",
        "#Función de crear la parte \"operacional\" de GradCam\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names,last_conv_layer):\n",
        "    \n",
        "    # Modelo que mapea la imagen de entrada a la última capa convolucional dónde se calculará la activación\n",
        "    conv_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "    \n",
        "    p=0\n",
        "    predictions = []\n",
        "\n",
        "    # Modelo que mapea las activaciones a la salida final\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "        \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "        # Calcula activacion del modelo base convolucional\n",
        "        last_conv_layer_output = conv_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        \n",
        "        # Calcula la predicción con modelo clasificador, para la clase más probable\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class = int(np.array(top_pred_index))\n",
        "        p = p + top_class\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "        predictions.append(top_class_channel)\n",
        "\n",
        "    # Obtenemos el gradiente en la capa final clasificadora con respecto a la salida del modelo base convolucional\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Vector de pesos: medias del gradiente por capas,\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    # salida de la última capa convolucional\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    \n",
        "    # saliencia es la respuesta promedio de la última capa convolucional\n",
        "    saliency = np.mean(last_conv_layer_output, axis=-1)\n",
        "    saliency = np.maximum(saliency, 0) / np.max(saliency)\n",
        "    \n",
        "    # Multiplicación de cada canal por el vector de pesos\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "        \n",
        "    # Heatmap: promedio de cada canal por su peso\n",
        "    grad_cam = np.mean(last_conv_layer_output, axis=-1)\n",
        "    grad_cam = np.maximum(grad_cam, 0) / np.max(grad_cam)\n",
        "    return grad_cam,saliency,predictions,top_class\n",
        "\n",
        "#Función de representar la imagen en una ventana emergente y guardarla en la carpeta elegida\n",
        "def show_hotmap (img_path, heatmap, title='Heatmap', alpha=0.6, cmap='jet', axisOnOff='off'):\n",
        "    cam_path = r'C:\\Users\\pop1md\\Desktop\\NO_segmentacion\\Pruebaaa\\1.jpg'\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "    superimposed_img.save(cam_path)\n",
        "    Image.open(cam_path).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sv25uNcKRf6"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 40\n",
        "\n",
        "imgOK_path = r'/content/drive/MyDrive/TFG/Fotos latas/OK'\n",
        "imgNOK_path = r'/content/drive/MyDrive/TFG/Fotos latas/NOK'\n",
        "dirListingOK = os.listdir(imgOK_path)\n",
        "dirListingNOK = os.listdir(imgNOK_path)\n",
        "nOK = len(dirListingOK)\n",
        "nNOK = len(dirListingNOK)\n",
        "\n",
        "#Definimos el dataset ya definido entre imágenes OK y NOK\n",
        "data_dir = r'/content/drive/MyDrive/TFG/Fotos latas'\n",
        "def build_dataset(subset, validation_split=0.3):\n",
        "  return tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      data_dir,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      subset=subset,\n",
        "      image_size=(300,300),\n",
        "      shuffle=True,\n",
        "      seed=100,\n",
        "      validation_split=validation_split)\n",
        "\n",
        "#Especificamos que este Dataset de imágenes son las que utilizaremos para el entrenamiento\n",
        "train_ds = build_dataset(subset=\"training\")\n",
        "class_names = tuple(train_ds.class_names)\n",
        "train_size = train_ds.cardinality().numpy()\n",
        "train_ds = train_ds.unbatch().batch(BATCH_SIZE)\n",
        "\n",
        "normalization_layer = tf.keras.layers.Layer()\n",
        "preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
        "train_ds = train_ds.map(lambda images, labels:\n",
        "                        (preprocessing_model(images), labels))\n",
        "\n",
        "#Especificamos que este otro Dataset son las que utilizaremos para la validación\n",
        "val_ds = build_dataset(subset=\"validation\")\n",
        "valid_size = val_ds.cardinality().numpy()\n",
        "val_ds = val_ds.unbatch().batch(BATCH_SIZE)\n",
        "val_ds = val_ds.map(lambda images, labels:\n",
        "                    (normalization_layer(images), labels))\n",
        "\n",
        "#Seleccionamos el modelo que vamos a utilizar y representamos el summary\n",
        "modelvgg16 = VGG16(include_top=False,\n",
        "              input_shape=(300,300,3),\n",
        "              weights=None,\n",
        "              classes=2)\n",
        "\n",
        "#Modificamos las últimas capas de salida para sólo obtener 2 posibles outputs\n",
        "x = modelvgg16.output\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(units=4096, activation='relu')(x)\n",
        "x = layers.Dense(units=4096, activation='relu')(x)\n",
        "x = layers.Dense(units=2, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(modelvgg16.input, x)\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer='adadelta',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ahora viene la parte de reproducir el GradCam, para ello asignamos nombres a diferentes capas\n",
        "last_layer_output = model.layers[-1].output\n",
        "last_conv_layer = model.layers[-6]\n",
        "last_conv_layer_name = 'block5_conv3'\n",
        "classifier_layer_names =  ['block5_pool',\n",
        "                            'flatten',\n",
        "                            'dense',\n",
        "                            'dense_1',\n",
        "                            'dense_2']\n",
        "\n",
        "\n",
        "#Cargamos las imágenes sobre las que vamos a aplicar el GradCam seleccionando todo el fichero\n",
        "img_size = (300,300)\n",
        "folder_path_o = r'/content/drive/MyDrive/TFG/Fotos latas/OK/*.jpg'\n",
        "folder_path_n = r'/content/drive/MyDrive/TFG/Fotos latas/NOK/*.jpg'\n",
        "fileo_with_path_list = glob.glob(folder_path_o)         #glob.glob nos permites obtener el nombre\n",
        "filen_with_path_list = glob.glob(folder_path_n)         #de la imagen junto con el path completo\n",
        "\n",
        "#Entrenamos y validamos el modelo (parte más larga)\n",
        "hist = model.fit_generator(\n",
        "    train_ds,\n",
        "    epochs=80,\n",
        "    verbose = 1,\n",
        "    validation_data = val_ds).history\n",
        "\n",
        "#Recorremos cada una de las imágenes para ver su MAPA DE CALOR GRADCAM\n",
        "\n",
        "n_numbero = 0\n",
        "r_preds=[]\n",
        "t_class = []\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for fileo in fileo_with_path_list:\n",
        "    n_numbero = n_numbero + 1\n",
        "    imgo = Image.open(fileo)\n",
        "    img_path = fileo\n",
        "\n",
        "    img_array = get_img_array(img_path,img_size)\n",
        "    grad_cam, saliency, predictions, top_class = make_gradcam_heatmap(img_array,\n",
        "                                                  model,\n",
        "                                                  last_layer_output,\n",
        "                                                  classifier_layer_names,\n",
        "                                                  last_conv_layer)\n",
        "    \n",
        "    show_hotmap(img_path, heatmap=grad_cam, title=f'Grad Cam: {model.name}')\n",
        "    show_hotmap(img_path, heatmap=saliency, title=f'Saliencia: {model.name}')\n",
        "\n",
        "    r_preds.append(predictions)\n",
        "    t_class.append(top_class)\n",
        "    \n",
        "n_numbern = 100000\n",
        "for filen in filen_with_path_list:\n",
        "    n_numbern = n_numbern + 1\n",
        "    imgn = Image.open(filen)\n",
        "    img_path = filen\n",
        "\n",
        "    img_array = get_img_array(img_path,img_size)\n",
        "    grad_cam, saliency, predictions, top_class = make_gradcam_heatmap(img_array,\n",
        "                                                  model,\n",
        "                                                  last_layer_output,\n",
        "                                                  classifier_layer_names,\n",
        "                                                  last_conv_layer)\n",
        "    \n",
        "    show_hotmap(img_path, heatmap=grad_cam, title=f'Grad Cam: {model.name}')\n",
        "    show_hotmap(img_path, heatmap=saliency, title=f'Saliencia: {model.name}')\n",
        "\n",
        "    r_preds.append(predictions)\n",
        "    t_class.append(top_class)\n",
        "\n",
        "labels = np.hstack((np.ones(nOK), np.zeros(nNOK)))\n",
        "print(t_class)\n",
        "print(labels)\n",
        "\n",
        "conf_matrix = tf.math.confusion_matrix(labels=labels,\n",
        "                                        predictions=t_class,\n",
        "                                        num_classes=2,\n",
        "                                        weights=None)\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "wUlvU9aEeIBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxwuo9eriEif"
      },
      "outputs": [],
      "source": [
        "# Creamos una lista dónde aparezca la foto, y si es un FP, FN, VP o VN\n",
        "\n",
        "l_labels=[]\n",
        "for elem in labels:\n",
        "  l_labels.append(elem)\n",
        "indices_NOK=[]\n",
        "V_P=0\n",
        "V_N=0\n",
        "F_P=0\n",
        "F_N=0\n",
        "for elem in range(len(l_labels)):\n",
        "  if elem<len(fileo_with_path_list):\n",
        "    image_name=fileo_with_path_list[elem]\n",
        "  else:\n",
        "    image_name=filen_with_path_list[elem-len(fileo_with_path_list)]\n",
        "\n",
        "  dif= l_labels[elem]-t_class[elem]\n",
        "  if dif==0 and l_labels[elem]==1:\n",
        "    V_P=V_P+1\n",
        "  elif dif==0 and l_labels[elem]==0:\n",
        "    V_N=V_N+1\n",
        "  elif dif==1:\n",
        "    image_name = fileo_with_path_list[elem]\n",
        "    indices_NOK.append([elem, image_name, 'Falso Negativo'])\n",
        "    F_P=F_P+1\n",
        "  elif dif==-1:\n",
        "    indices_NOK.append([elem, image_name, 'Falso Positivo'])\n",
        "    F_N=F_N+1\n",
        "print([V_P, F_P, F_N, V_N])\n",
        "print(indices_NOK)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Representamos el mapa de saliencia y el descenso de gradiente para comprobar que se fija en la parte correcta\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for filen in indices_NOK:\n",
        "    n_numbern = n_numbern + 1\n",
        "    imgn = Image.open(filen[1])\n",
        "    img_path = filen[1]\n",
        "\n",
        "    img_array = get_img_array(img_path,img_size)\n",
        "    grad_cam, saliency, predictions, top_class = make_gradcam_heatmap(img_array,\n",
        "                                                  model,\n",
        "                                                  last_layer_output,\n",
        "                                                  classifier_layer_names,\n",
        "                                                  last_conv_layer)\n",
        "    show_hotmap(img_path, heatmap=grad_cam, title=f'Grad Cam: {model.name}')\n",
        "    show_hotmap(img_path, heatmap=saliency, title=f'Saliencia: {model.name}')\n",
        "    print(filen)\n",
        "    plt.subplot(121)\n",
        "    plt.title('GradCam')\n",
        "    plt.imshow(grad_cam, 'jet')\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(saliency, 'jet')\n",
        "    plt.title('Saliencia')\n",
        "    plt.show()\n",
        "    img = mpimg.imread(filen[1])\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TMYo8FMCQuXA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}